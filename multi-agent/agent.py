"""
Multi-Agent System with Memory, Rollback, and Visualization
- 6 Agents: Chat, Code, DB, Crawler, RAG, Context Engineer
- Memory: SQLite Checkpointer for conversation history
- Snapshots: Visualized as PNG/HTML with Mermaid diagrams
- Error Recovery: Automatic retry + fallback to other agents
- Upgraded to LangChain 1.0.5 and LangGraph 1.0.0 with Middleware
"""

import sys
import os
import json
from langgraph.checkpoint.memory import MemorySaver
from datetime import datetime
from typing import Annotated, Sequence, Dict, Any, Optional
from typing_extensions import TypedDict
from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, SystemMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, MessagesPlaceholder
from langgraph.graph import StateGraph, START, END
from langgraph.errors import GraphRecursionError
import operator
import logging
from pathlib import Path

import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# === é…ç½® ===
from dotenv import load_dotenv
load_dotenv()

from config import DASHSCOPE_API_KEY
DASHSCOPE_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"

# è°ƒè¯•
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === å¯¼å…¥ Prompt å’Œ Tools ===
from prompt import (
    db_system_prompt, supervisor_system_prompt, rag_system_prompt, 
    agentic_context_system_prompt, crawler_system_prompt, coder_system_prompt, chat_system_prompt
)
from tools import (
    # Chat tools
    read_file, create_file, str_replace, send_qq_email,
    # DB tools
    add_sale, delete_sale, update_sale, query_sales, query_table_schema, execute_sql,
    # Code tools
    python_repl, shell_exec,
    # Crawler tools
    get_nasdaq_top_gainers, get_crypto_sentiment_indicators, resilient_tavily_search,
    # RAG tools
    list_files_metadata,
    # Context tools
    save_context_snapshot, list_context_snapshots, evaluate_output, restore_snapshot
)

# LangChain 1.0 Imports for Agents and Middleware
from langchain.agents import create_agent, AgentMiddleware
from langchain.agents.middleware import SummarizationMiddleware, HumanInTheLoopMiddleware
from langchain_openai import ChatOpenAI
from langchain.agents.middleware.types import ModelRequest, ModelResponse, ToolCallRequest, ToolCallResponse

# === AgentStateï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒå¿«ç…§ã€é”™è¯¯çŠ¶æ€å’Œreasonï¼‰===
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    sender: str | None
    next: str | None
    reason: str | None  # Added for supervisor reason
    error_count: int  # é”™è¯¯è®¡æ•°ï¼Œç”¨äºé‡è¯•
    snapshot_id: str | None  # å½“å‰å¿«ç…§ ID
    memory_key: str  # å¯¹è¯çº¿ç¨‹ ID

# === LLMs é…ç½® ===
def create_llm(model_name="qwen-plus", temperature=0.1):
    """åˆ›å»ºç»Ÿä¸€çš„ Qwen LLM"""
    return ChatOpenAI(
        model=model_name,
        api_key=DASHSCOPE_API_KEY,
        base_url=DASHSCOPE_BASE_URL,
        temperature=temperature
    )

supervisor_llm = create_llm(temperature=0.0)
chat_llm = create_llm()
db_llm = create_llm(temperature=0.0)  # DB éœ€è¦ç¡®å®šæ€§
coder_llm = create_llm(temperature=0.3)  # ä»£ç ç”Ÿæˆéœ€è¦åˆ›é€ æ€§
crawler_llm = create_llm()
rag_llm = create_llm(temperature=0.1)
context_engineer_llm = create_llm(temperature=0.2)

# === è‡ªå®šä¹‰ Middleware for Context Engineer ===
class CustomContextMiddleware(AgentMiddleware):
    def before_model(self, request: ModelRequest) -> ModelRequest:
        # Dynamic Context Injection: Add/remove history based on query relevance
        query = request.messages[-1].content if request.messages else ""
        relevant_messages = [msg for msg in request.messages[:-1] if any(word in msg.content.lower() for word in query.lower().split())]  # Simple keyword relevance
        request.messages = relevant_messages + [request.messages[-1]]
        logger.info("Dynamic context injected based on query relevance.")
        return request

    def after_model(self, response: ModelResponse) -> ModelResponse:
        # Context Evaluation & Compression: Evaluate output and compress redundant context
        eval_result = evaluate_output("Correctness;Completeness;No Hallucination", response.content)
        if not eval_result.get("passed", False):
            logger.warning(f"Output evaluation failed: {eval_result['reason']}")
            # Compress: Summarize last 5 messages (using prebuilt if available)
            summarizer = SummarizationMiddleware(model=context_engineer_llm, max_tokens_before_summary=500)
            response.runtime.messages = summarizer.after_model(response).runtime.messages  # Compress
        logger.info("Context evaluated and compressed if needed.")
        return response

    def wrap_tool_call(self, request: ToolCallRequest, handler: Callable[[ToolCallRequest], ToolCallResponse]) -> ToolCallResponse:
        # Snapshot Management: Save/restore pre-tool call
        snapshot_id = save_context_snapshot({
            "messages": [m.content for m in request.runtime.messages[-5:]],
            "sender": request.runtime.sender,
            "timestamp": datetime.now().isoformat()
        })
        request.runtime.snapshot_id = snapshot_id
        logger.info(f"Pre-tool snapshot saved: {snapshot_id}")

        # Human-in-the-Loop: Pause for confirmation
        human_mw = HumanInTheLoopMiddleware(interrupt_on={"all_tools": {"allowed_decisions": ["approve", "edit", "reject"]}})
        if human_mw.wrap_tool_call(request, lambda r: r).decision != "approve":  # Simulate pause
            user_input = input("Human approval needed. Approve? (y/n/edit): ")
            if user_input.lower() == "n":
                restore_snapshot(snapshot_id)  # Rollback on reject
                raise ValueError("Human rejected tool call.")
            elif user_input.lower() == "edit":
                # Edit logic (simplified)
                request.tool_calls[0].args["query"] = input("Edit query: ")

        try:
            result = handler(request)
        except Exception as e:
            # Error Recovery: Rollback on error/hallucination
            logger.error(f"Tool call error: {e}. Rolling back.")
            restore_snapshot(snapshot_id)
            result = ToolCallResponse(error=str(e))
        return result

    def wrap_model_call(self, request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]) -> ModelResponse:
        try:
            result = handler(request)
        except Exception as e:
            # Error Recovery: Detect hallucination/error and rollback
            logger.error(f"Model call error: {e}. Attempting recovery.")
            if request.runtime.snapshot_id:
                restore_snapshot(request.runtime.snapshot_id)
            result = ModelResponse(content=f"Recovered from error: {e}")
        return result

    def after_agent(self, response: Any) -> Any:
        # Trigger visualization after agent
        if response.get("snapshot_id"):
            visualize_snapshot(response["snapshot_id"])
        return response

# === åˆ›å»º Agentï¼ˆä½¿ç”¨ LangChain 1.0 create_agent + Middleware for Context Engineerï¼‰===
def create_resilient_agent(llm, tools, system_prompt, agent_name="Agent", middleware=None):
    """åˆ›å»ºæ ‡å‡†åŒ– Agent with resilience"""
    system_msg = SystemMessagePromptTemplate.from_template(system_prompt)
    prompt = ChatPromptTemplate.from_messages([system_msg, MessagesPlaceholder(variable_name="messages")])
    return create_agent(
        model=llm,
        tools=tools,
        system_prompt=system_prompt,  # Passed directly in 1.0
        middleware=middleware or [],
        name=agent_name
    )

# 1. Chat Agent
chat_agent = create_resilient_agent(
    chat_llm,
    tools=[read_file, create_file, str_replace, send_qq_email],
    system_prompt=chat_system_prompt,
    agent_name="ChatAgent"
)

# 2. DB Agent
db_agent = create_resilient_agent(
    db_llm,
    tools=[add_sale, delete_sale, update_sale, query_sales, query_table_schema, execute_sql],
    system_prompt=db_system_prompt,
    agent_name="DBAgent"
)

# 3. Code Agent
code_agent = create_resilient_agent(
    coder_llm,
    tools=[python_repl, create_file, read_file, str_replace, shell_exec, resilient_tavily_search],
    system_prompt=coder_system_prompt,
    agent_name="CodeAgent"
)

# 4. Crawler Agent
crawler_agent = create_resilient_agent(
    crawler_llm,
    tools=[get_nasdaq_top_gainers, get_crypto_sentiment_indicators, resilient_tavily_search, create_file],
    system_prompt=crawler_system_prompt,
    agent_name="CrawlerAgent"
)

# 5. RAG Agent
rag_agent = create_resilient_agent(
    rag_llm,
    tools=[list_files_metadata, read_file],
    system_prompt=rag_system_prompt.format(file_path=os.getcwd() + "\\documents"),
    agent_name="RAGAgent"
)

# 6. Context Engineer (with Custom Middleware)
context_engineer = create_resilient_agent(
    context_engineer_llm,
    tools=[save_context_snapshot, list_context_snapshots, evaluate_output, restore_snapshot],
    system_prompt=agentic_context_system_prompt,
    agent_name="ContextEngineer",
    middleware=[CustomContextMiddleware(), SummarizationMiddleware(model=context_engineer_llm)]
)

# === æˆå‘˜é…ç½® ===
members = [
    "chat_agent", "code_agent", "db_agent", 
    "crawler_agent", "rag_agent", "context_engineer_agent"
]
options = members + ["FINISH"]

class Router(TypedDict):
    next: str
    reason: str  # Added for reason

# === Supervisorï¼ˆæ”¯æŒé”™è¯¯æ¢å¤ + Reason Outputï¼‰===
def supervisor(state: AgentState) -> Dict[str, Any]:
    """Supervisor with error recovery logic and reason output"""
    try:
        system_msg = SystemMessage(
            content=supervisor_system_prompt.format(members=", ".join(members))
        )
        messages = [system_msg] + state["messages"]
        
        response = supervisor_llm.with_structured_output(Router).invoke(messages)
        next_worker = response["next"]
        reason = response["reason"]
        logger.info(f"Supervisor reason: {reason}")
        
        # é”™è¯¯æ¢å¤ï¼šå¦‚æœä¹‹å‰æœ‰é”™è¯¯ï¼Œä¼˜å…ˆè®© ContextEngineer æ£€æŸ¥
        if state.get("error_count", 0) > 0:
            logger.warning(f"Previous errors detected ({state['error_count']}), checking context...")
            next_worker = "context_engineer_agent" if next_worker != "FINISH" else "FINISH"
            reason += " (rerouted due to errors)"
        
        return {"next": next_worker, "reason": reason, "error_count": 0}  # é‡ç½®é”™è¯¯è®¡æ•°
        
    except Exception as e:
        logger.error(f"Supervisor error: {e}")
        # å›é€€åˆ° ContextEngineer ä¿®å¤
        return {"next": "context_engineer_agent", "reason": "Fallback due to supervisor error", "error_count": state.get("error_count", 0) + 1}

# === é€šç”¨ Agent èŠ‚ç‚¹ï¼ˆå¸¦é”™è¯¯æ¢å¤ï¼Œé›†æˆ Middlewareè¡Œä¸ºï¼‰===
def create_resilient_node(agent):
    """åˆ›å»ºå¸¦é”™è¯¯æ¢å¤çš„èŠ‚ç‚¹å‡½æ•°"""
    def node(state: AgentState) -> Dict[str, Any]:
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # æ‰§è¡Œ Agent (LangChain 1.0 invoke)
                result = agent.invoke(state)
                
                # ä¿å­˜å¿«ç…§ï¼ˆæ¯ 3 è½®å¯¹è¯ä¸€æ¬¡ï¼Œmiddleware handles visualizationï¼‰
                if len(state["messages"]) % 3 == 0:
                    snapshot_id = save_context_snapshot({
                        "messages": [m.content for m in state["messages"][-5:]],  # æœ€è¿‘5æ¡
                        "sender": state["sender"],
                        "timestamp": datetime.now().isoformat()
                    })
                    state["snapshot_id"] = snapshot_id
                    logger.info(f"Snapshot saved: {snapshot_id}")
                
                return {
                    "messages": result["messages"],
                    "sender": agent.name,
                    "error_count": 0,
                    "snapshot_id": state.get("snapshot_id")
                }
                
            except GraphRecursionError:
                logger.warning("Recursion detected, breaking loop")
                return {"messages": [AIMessage(content="Task completed to avoid infinite loop.")], "sender": agent.name}
                
            except Exception as e:
                logger.error(f"Attempt {attempt + 1} failed for {agent.name}: {e}")
                if attempt == max_retries - 1:
                    # æœ€ç»ˆå¤±è´¥ï¼šå›æ»šåˆ°ä¸Šä¸€ä¸ªå¿«ç…§
                    if state.get("snapshot_id"):
                        rollback_msg = restore_snapshot(state["snapshot_id"])
                        return {
                            "messages": [AIMessage(content=f"Error recovered via rollback: {rollback_msg}")],
                            "sender": "Recovery",
                            "error_count": state.get("error_count", 0) + 1
                        }
                    else:
                        return {
                            "messages": [AIMessage(content=f"Critical error after {max_retries} attempts: {e}. Please clarify your request.")],
                            "sender": "ErrorHandler",
                            "error_count": state.get("error_count", 0) + 1
                        }
                
                # é‡è¯•ï¼šæ¸…ç†éƒ¨åˆ†çŠ¶æ€
                state["messages"] = state["messages"][-10:]  # ä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯
                continue
    
    return node

# === åˆ›å»ºèŠ‚ç‚¹ ===
chat_node = create_resilient_node(chat_agent)
db_node = create_resilient_node(db_agent)
code_node = create_resilient_node(code_agent)
crawler_node = create_resilient_node(crawler_agent)
rag_node = create_resilient_node(rag_agent)
context_node = create_resilient_node(context_engineer)  # Middleware applied here

# === æ„å»º Graphï¼ˆå¸¦è®°å¿†ï¼‰===
def build_graph_with_memory():
    """æ„å»ºå¸¦ Checkpointer çš„ Graph"""
    # åˆå§‹åŒ– Checkpointerï¼ˆSQLite è®°å¿†ï¼‰
    os.makedirs("./memory", exist_ok=True)
    memory = MemorySaver()
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("supervisor", supervisor)
    workflow.add_node("chat_agent", chat_node)
    workflow.add_node("db_agent", db_node)
    workflow.add_node("code_agent", code_node)
    workflow.add_node("crawler_agent", crawler_node)
    workflow.add_node("rag_agent", rag_node)
    workflow.add_node("context_engineer_agent", context_node)
    
    # è¾¹ï¼šAgent â†’ Supervisor
    for member in members:
        workflow.add_edge(member, "supervisor")
    
    # START â†’ Supervisor
    workflow.add_edge(START, "supervisor")
    
    # æ¡ä»¶è¾¹
    workflow.add_conditional_edges(
        "supervisor",
        lambda state: state["next"],
        {
            "chat_agent": "chat_agent",
            "db_agent": "db_agent",
            "code_agent": "code_agent",
            "crawler_agent": "crawler_agent",
            "rag_agent": "rag_agent",
            "context_engineer_agent": "context_engineer_agent",
            "FINISH": END,
        }
    )
    
    # ç¼–è¯‘ï¼ˆå¸¦è®°å¿†ï¼‰
    graph = workflow.compile(checkpointer=memory)
    graph.name = "Resilient Multi-Agent System"
    return graph, memory

# === å¿«ç…§å¯è§†åŒ–å·¥å…· ===
def visualize_snapshot(snapshot_id: str, output_dir: str = "./snapshots"):
    """å¯è§†åŒ–å¿«ç…§ï¼šç”Ÿæˆ Mermaid PNG + HTML"""
    try:
        os.makedirs(output_dir, exist_ok=True)
        
        # å‡è®¾å¿«ç…§åŒ…å«æ¶ˆæ¯æµ
        snapshot_data = json.loads(open(f"./contexts/{snapshot_id}.json").read())
        messages = snapshot_data.get("messages", [])
        
        # ç”Ÿæˆ Mermaid æµç¨‹å›¾
        mermaid_code = "graph TD\n"
        for i, msg in enumerate(messages):
            sender = msg.get("sender", "Unknown")
            content = msg[:50] + "..." if len(msg) > 50 else msg  # æˆªæ–­
            node_id = f"N{i}"
            mermaid_code += f'    {node_id}["{sender}: {content}"]\n'
            if i > 0:   
                mermaid_code += f"    N{i-1} --> {node_id}\n"
        
        # ä¿å­˜ Mermaid
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head><script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script></head>
        <body>
            <div class="mermaid">
                {mermaid_code}
            </div>
            <script>mermaid.initialize({{startOnLoad:true}});</script>
        </body>
        </html>
        """
        
        html_path = f"{output_dir}/{snapshot_id}.html"
        png_path = f"{output_dir}/{snapshot_id}.png"  # éœ€è¦é¢å¤–å·¥å…·ç”Ÿæˆ PNG
        
        with open(html_path, "w") as f:
            f.write(html_content)
        
        logger.info(f"Snapshot visualized: {html_path}")
        return html_path
        
    except Exception as e:
        logger.error(f"Visualization failed: {e}")
        return None

# === å…¨å±€ Graph ===
graph, memory = build_graph_with_memory()

# === å·¥å…·å‡½æ•°ï¼šå¸¦è®°å¿†çš„è°ƒç”¨ ===
def invoke_with_memory(query: str, thread_id: str = None, config: Optional[Dict] = None):
    """å¸¦è®°å¿†çš„ Graph è°ƒç”¨ï¼Œæ”¯æŒå›æ»š"""
    if thread_id is None:
        thread_id = str(datetime.now().timestamp())
    
    config = config or {"configurable": {"thread_id": thread_id}}
    
    try:
        # æµå¼æ‰§è¡Œï¼ˆå®æ—¶è¾“å‡ºï¼‰
        final_state = None
        for chunk in graph.stream(
            {"messages": [HumanMessage(content=query)], "memory_key": thread_id},
            config=config
        ):
            print(chunk) 
            final_state = chunk
        
        # å¯è§†åŒ–æœ€ç»ˆå¿«ç…§ (middleware already handles, but fallback)
        if final_state and final_state.get("snapshot_id"):
            viz_path = visualize_snapshot(final_state["snapshot_id"])
            if viz_path:
                print(f"ğŸ“Š Snapshot visualization: {viz_path}")
        
        return final_state
        
    except Exception as e:
        logger.error(f"Invocation failed: {e}")
        # ç´§æ€¥å›æ»šï¼šæ¢å¤åˆ°æœ€æ–°å¿«ç…§
        snapshots = list_context_snapshots()
        if snapshots:
            latest = snapshots[-1]
            rollback_msg = restore_snapshot(latest['id'])
            print(f"ğŸš¨ Emergency rollback: {rollback_msg}")
        raise

# === æµ‹è¯• ===
if __name__ == "__main__":
    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡ç›®å½•
    os.makedirs("./contexts", exist_ok=True)
    os.makedirs("./snapshots", exist_ok=True)
    os.makedirs("./documents", exist_ok=True)
    
    # æµ‹è¯• 1ï¼šç®€å•å¯¹è¯
    print("=== æµ‹è¯• 1ï¼šç®€å•å¯¹è¯ ===")
    result1 = invoke_with_memory("ä½ å¥½ï¼Œæˆ‘æ˜¯é‡‘èåˆ†æå¸ˆ")
    print(f"Final response: {result1['messages'][-1].content if result1 else 'Failed'}")
    
    # æµ‹è¯• 2ï¼šå¤æ‚æŸ¥è¯¢ï¼ˆè§¦å‘å·¥å…· + é”™è¯¯æ¢å¤ï¼‰
    print("\n=== æµ‹è¯• 2ï¼šçº³æ–¯è¾¾å…‹æŸ¥è¯¢ + æ¨¡æ‹Ÿé”™è¯¯ ===")
    try:
        # æ¨¡æ‹Ÿä¸€ä¸ªå¯èƒ½å‡ºé”™çš„æŸ¥è¯¢
        result2 = invoke_with_memory("åˆ†æä»Šå¤©çº³æ–¯è¾¾å…‹æ¶¨å¹…å‰3çš„è‚¡ç¥¨ï¼Œç”ŸæˆæŠ¥å‘Šã€‚å¦‚æœå‡ºé”™è¯·è‡ªåŠ¨æ¢å¤ã€‚")
        print(f"Success: {result2['messages'][-1].content[:100] if result2 else 'Failed'}...")
    except Exception as e:
        print(f"Expected error handled: {e}")
    
    # æµ‹è¯• 3ï¼šåŠ è½½è®°å¿†
    print("\n=== æµ‹è¯• 3ï¼šåŠ è½½è®°å¿†ç»§ç»­å¯¹è¯ ===")
    thread_id = "test_thread_123"
    invoke_with_memory("ä¹‹å‰æˆ‘é—®äº†çº³æ–¯è¾¾å…‹ï¼Œç°åœ¨å¸®æˆ‘æŸ¥æ•°æ®åº“é‡Œçš„é”€å”®æ•°æ®", thread_id=thread_id)
    
    print("\nğŸ‰ Multi-Agent System with Memory & Recovery is ready!")
    print("Run: result = invoke_with_memory('your query', thread_id='unique_id')")