from loaders import load_pdf_with_tables
from chunkers import get_semantic_splitter
from retrievers import get_bm25_retriever, get_vector_retriever
from query_engine import build_query_engine
from pathlib import Path
import pickle

import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

from dotenv import load_dotenv
env_path = Path(__file__).parent / ".env"
load_dotenv(dotenv_path=env_path)

from config import LLAMA_CLOUD_API_KEY
from config import DASHSCOPE_API_KEY
# print(f"main LLAMA_CLOUD_API_KEY: {LLAMA_CLOUD_API_KEY}")

PDF_DIR = r"E:\\model\\RAG\\report"
CHROMA_PATH = "E:\\model\\RAG\\chroma_db"
NODES_CACHE = "E:\\model\\RAG\\nodes.pkl"

def main():
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æŒä¹…åŒ–å‘é‡åº“å’Œ nodes ç¼“å­˜
    has_chroma = os.path.exists(CHROMA_PATH) and os.listdir(CHROMA_PATH)
    has_nodes = os.path.exists(NODES_CACHE)

    if has_chroma and has_nodes:
        print("ğŸ” Loading from persistent storage (Chroma + nodes.pkl)...")
        documents = None
        nodes = None
        # å…ˆåŠ è½½ nodesï¼ˆç”¨äº BM25ï¼‰
        with open(NODES_CACHE, "rb") as f:
            nodes = pickle.load(f)
    else:
        print("1. Loading PDFs with LlamaParse...")
        documents = load_pdf_with_tables(PDF_DIR)
        print(f"Loaded {len(documents)} chunks (with table-aware parsing).")

        print("2. Chunking...")
        splitter = get_semantic_splitter()
        nodes = splitter.get_nodes_from_documents(documents)

        # ä¿å­˜ nodes.pklï¼ˆç”¨äºåç»­è·³è¿‡ PDF è§£æï¼‰
        with open(NODES_CACHE, "wb") as f:
            pickle.dump(nodes, f)
        print(f"âœ… Cached nodes to {NODES_CACHE}")

    print("3. Building retrievers...")
    # å‘é‡æ£€ç´¢å™¨ï¼šè‡ªåŠ¨å¤„ç† Chroma æŒä¹…åŒ–ï¼ˆåœ¨ retrievers.py ä¸­å®ç°ï¼‰
    vector_retriever = get_vector_retriever(nodes, top_k=15)

    # BM25 æ£€ç´¢å™¨ï¼šä½¿ç”¨å·²åŠ è½½æˆ–åˆšç”Ÿæˆçš„ nodes
    bm25_retriever = get_bm25_retriever(nodes, top_k=15)

    print("âœ… RAG system ready!")
    while True:
        query = input("\nYour question (or 'quit'): ").strip()
        if query.lower() == 'quit':
            break
        query_engine = build_query_engine(bm25_retriever, vector_retriever, query)
        response = query_engine.query(query)
        print("\nAnswer:", response.response)
        print("\nSources:")
        for i, node in enumerate(response.source_nodes, 1):
            meta = node.node.metadata
            print(f"{i}. {meta.get('company', 'Unknown')} ({meta.get('fiscal_year', 'Unknown')})")
            preview = node.node.text.replace("\n", " ")[:150]
            print(f"   Preview: {preview}...")

if __name__ == "__main__":
    main()