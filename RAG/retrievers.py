from llama_index.retrievers.bm25 import BM25Retriever
from llama_index.core import VectorStoreIndex
from llama_index.core.embeddings import resolve_embed_model
from llama_index.embeddings.dashscope import DashScopeEmbedding
from llama_index.core.vector_stores import MetadataFilter, MetadataFilters, ExactMatchFilter
from config import EMBEDDING_MODEL, DASHSCOPE_API_KEY
import jieba
import chromadb
from chromadb.errors import NotFoundError
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.core import StorageContext

CHROMA_PATH = "E:\\model\\RAG\\chroma_db"

def get_bm25_retriever(nodes, top_k=5, filters=None):
    def tokenize(text: str):
        return jieba.lcut(text)
    
    return BM25Retriever.from_defaults(
        nodes=nodes,
        tokenizer=tokenize,
        similarity_top_k=top_k,
        filters=filters  # æ³¨æ„ï¼šBM25Retriever 0.14.10 å¯èƒ½ä¸æ”¯æŒ filtersï¼Œå°†åœ¨ HybridRetriever ä¸­åè¿‡æ»¤
    )

def get_vector_retriever(nodes=None, top_k=5, filters=None, persist_dir=CHROMA_PATH):
    """
    å¦‚æœ persist_dir å­˜åœ¨ä¸”éç©ºï¼Œåˆ™åŠ è½½å·²æœ‰ç´¢å¼•ï¼›
    å¦åˆ™ç”¨ nodes æ„å»ºæ–°ç´¢å¼•å¹¶æŒä¹…åŒ–ã€‚
    """
    embed_model = DashScopeEmbedding(
        model_name=EMBEDDING_MODEL,
        api_key=DASHSCOPE_API_KEY,
        batch_size=10  # å¿…é¡»ä¿ç•™ï¼
    )

    # åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯ï¼ˆæŒä¹…åŒ–ï¼‰
    db = chromadb.PersistentClient(path=persist_dir)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ collection
    collection_name = "annual_reports"
    try:
        chroma_collection = db.get_collection(collection_name)
        # åŠ è½½å·²æœ‰ç´¢å¼•
        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
        index = VectorStoreIndex.from_vector_store(
            vector_store, embed_model=embed_model
        )
        print(f"âœ… Loaded existing index from {persist_dir}")
    except NotFoundError:
        # é¦–æ¬¡è¿è¡Œï¼šæ„å»ºæ–°ç´¢å¼•
        if nodes is None:
            raise ValueError("No existing index found and no nodes provided to build one.")
        print(f"ğŸ†• Building new index and saving to {persist_dir}...")
        chroma_collection = db.create_collection(collection_name)
        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
        storage_context = StorageContext.from_defaults(vector_store=vector_store)
        index = VectorStoreIndex(
            nodes,
            embed_model=embed_model,
            storage_context=storage_context,
            show_progress=True
        )
        # è‡ªåŠ¨æŒä¹…åŒ–ï¼ˆChroma PersistentClient ä¼šå†™å…¥ç£ç›˜ï¼‰
    
    return index.as_retriever(similarity_top_k=top_k, filters=filters)

# ä¸ºå…¼å®¹æ€§ï¼Œæˆ‘ä»¬åœ¨ HybridRetriever ä¸­æ‰‹åŠ¨è¿‡æ»¤ BM25 ç»“æœ
def filter_nodes_by_metadata(nodes, filters_dict):
    """ç®€æ˜“å…ƒæ•°æ®è¿‡æ»¤ï¼ˆç”¨äº BM25ï¼‰"""
    if not filters_dict:
        return nodes
    filtered = []
    for node in nodes:
        match = True
        for key, value in filters_dict.items():
            if node.metadata.get(key) != value:
                match = False
                break
        if match:
            filtered.append(node)
    return filtered