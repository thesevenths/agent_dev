from typing import List
import jieba
import chromadb
from chromadb.errors import NotFoundError
from llama_index.core import VectorStoreIndex
from llama_index.core.schema import BaseNode
import uuid

# å°è¯•å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ llama-index å¯¼å…¥
try:
    from llama_index.retrievers.bm25 import BM25Retriever
except Exception as e:
    raise ImportError("éœ€è¦å®‰è£…å…¼å®¹çš„ llama-index åŒ…ï¼Œæˆ–æ£€æŸ¥ç‰ˆæœ¬ã€‚è¯¦ç»†é”™è¯¯: " + str(e))

# å‘é‡ç´¢å¼•ç›¸å…³
try:
    from llama_index.core import VectorStoreIndex
    from llama_index.vector_stores.chroma import ChromaVectorStore
    from llama_index.core import StorageContext
except Exception:
    # å¦‚æœæœ‰ç‰ˆæœ¬å·®å¼‚ï¼Œè¿™é‡Œä¿ç•™å¯¼å…¥å¤±è´¥ä¿¡æ¯ä¾›è°ƒè¯•
    raise

# DashScope embeddingï¼ˆè‹¥ä¸éœ€è¦å¯æ”¹ä¸ºå…¶ä»– embeddingï¼‰
from config import EMBEDDING_MODEL, DASHSCOPE_API_KEY
try:
    from llama_index.embeddings.dashscope import DashScopeEmbedding
except Exception:
    DashScopeEmbedding = None  # å›é€€ï¼šå¦‚æœä¸å¯ç”¨ï¼Œåç»­æ„å»ºå‘é‡ç´¢å¼•æ—¶ä¼šæŠ¥æ›´æ˜ç¡®çš„é”™è¯¯

# å…¼å®¹ Document çš„å¯¼å…¥
try:
    from llama_index import Document
except Exception:
    try:
        from llama_index.schema import Document
    except Exception:
        from dataclasses import dataclass
        @dataclass
        class Document:
            text: str
            metadata: dict = None

# å…¼å®¹ TextNode çš„å¯¼å…¥
try:
    from llama_index.core.schema import TextNode
except Exception:
    try:
        from llama_index.schema import TextNode
    except Exception:
        # å¦‚æœå®åœ¨æ²¡æœ‰ï¼Œç”¨æœ€ç®€å…¼å®¹å®ç°ï¼Œä½†å¿…é¡»ç»§æ‰¿ BaseNodeï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            from llama_index.core.schema import BaseNode
        except Exception:
            from llama_index.schema import BaseNode  # å†å°è¯•ä¸€æ¬¡

        class TextNode(BaseNode):
            def __init__(self, text: str, metadata: dict = None, id_: str = None):
                from uuid import uuid4
                self._text = text
                self._metadata = metadata or {}
                self._id = id_ or str(uuid4())
                super().__init__(text=text, metadata=metadata, id_=self._id)

            @property
            def text(self) -> str:
                return self._text

            @property
            def metadata(self) -> dict:
                return self._metadata

            @property
            def node_id(self) -> str:
                return self._id

            def get_content(self, *args, **kwargs) -> str:
                return self.text

            def get_text(self) -> str:
                return self.text

            def get_metadata_str(self) -> str:
                return str(self.metadata)

# å…¼å®¹ SimpleNodeParser çš„å¯¼å…¥ï¼›è‹¥ä¸å­˜åœ¨åˆ™ä½¿ç”¨ç®€å•å›é€€å®ç°
try:
    from llama_index.node_parser import SimpleNodeParser
except Exception:
    import uuid
    class SimpleNodeParser:
        def get_nodes_from_documents(self, documents):
            nodes = []
            # åœ¨ get_nodes_from_documents ä¸­ï¼š
            for i, d in enumerate(documents):
                txt = getattr(d, "text", "") or ""
                meta = getattr(d, "metadata", {}) or {}
                source = meta.get("source", "unknown")
                
                # ä¼˜å…ˆä½¿ç”¨æ–‡æ¡£è‡ªå¸¦ IDï¼Œå¦åˆ™ç”¨ source + UUID
                doc_id = meta.get("item_id") or meta.get("table_id") or meta.get("source")
                if doc_id:
                    nid = f"{doc_id}_{str(uuid.uuid4())[:8]}"
                else:
                    nid = str(uuid.uuid4())
                
                node = TextNode(text=txt, metadata=meta, id_=nid)
                nodes.append(node)
            return nodes

CHROMA_PATH = "E:\\model\\RAG\\chroma_db"

def get_bm25_retriever(documents: list, top_k=5, filters=None):
    """
    ä½¿ç”¨ SimpleNodeParser å°† Document åˆ—è¡¨è½¬æ¢ä¸ºèŠ‚ç‚¹ï¼Œå†æ„å»º BM25Retrieverã€‚
    documents: list[llama_index.Document]
    """
    if not documents:
        raise ValueError("documents required for BM25 retriever")

    def tokenize(text: str):
        return jieba.lcut(text)

    parser = SimpleNodeParser()
    nodes = parser.get_nodes_from_documents(documents)

    return BM25Retriever.from_defaults(
        nodes=nodes,
        tokenizer=tokenize,
        similarity_top_k=top_k,
        filters=filters
    )

def get_vector_retriever(documents: list=None, top_k=5, filters=None, persist_dir=CHROMA_PATH):
    """
    å¦‚æœ persist_dir å­˜åœ¨ä¸”å«æœ‰ collectionï¼Œåˆ™åŠ è½½å·²æœ‰ç´¢å¼•ï¼›
    å¦åˆ™ç”¨ documents æ„å»ºæ–°ç´¢å¼•å¹¶æŒä¹…åŒ–ã€‚
    documents: list[llama_index.Document]
    """
    if DashScopeEmbedding is None:
        raise ImportError("DashScopeEmbedding ä¸å¯ç”¨ï¼Œè¯·å®‰è£…ç›¸åº” llama-index embeddings æˆ–ä¿®æ”¹ä¸ºå…¶å®ƒ embedding å®ç°ã€‚")

    embed_model = DashScopeEmbedding(
        model_name=EMBEDDING_MODEL,
        api_key=DASHSCOPE_API_KEY,
        batch_size=1  # æ”¹ä¸º 1ï¼Œç»™ API æ›´å¤šä½™é‡
    )

    # åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯ï¼ˆæŒä¹…åŒ–ï¼‰
    db = chromadb.PersistentClient(path=persist_dir)
    collection_name = "annual_reports"

    try:
        chroma_collection = db.get_collection(collection_name)
        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
        index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)
        print(f"âœ… Loaded existing index from {persist_dir}")
    except NotFoundError:
        if documents is None:
            raise ValueError("No existing index found and no documents provided to build one.")
        print(f"ğŸ†• Building new index and saving to {persist_dir}...")
        chroma_collection = db.create_collection(collection_name)
        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
        storage_context = StorageContext.from_defaults(vector_store=vector_store)

        parser = SimpleNodeParser()
        nodes = parser.get_nodes_from_documents(documents)
        # åˆ†æ‰¹ï¼Œæ¯æ‰¹æœ€å¤š 10 ä¸ª node
        batch_size = 10
        index = None
        for i in range(0, len(nodes), batch_size):
            batch = nodes[i:i + batch_size]
            if i == 0:
                index = VectorStoreIndex(
                    nodes=batch,
                    embed_model=embed_model,
                    storage_context=storage_context,
                    show_progress=True
                )
            else:
                index.insert_nodes(batch)
    return index.as_retriever(similarity_top_k=top_k, filters=filters)

def filter_nodes_by_metadata(nodes, filters_dict):
    """ç®€æ˜“å…ƒæ•°æ®è¿‡æ»¤ï¼ˆç”¨äº BM25ï¼‰"""
    if not filters_dict:
        return nodes
    filtered = []
    for node in nodes:
        meta = getattr(node, "metadata", {}) or {}
        match = True
        for key, value in filters_dict.items():
            if meta.get(key) != value:
                match = False
                break
        if match:
            filtered.append(node)
    return filtered